\chapter{Description of Problem}
\label{sec:description}

Ceph currently does not provide a mechanism to perform a full cluster
snapshot, and thus cannot support consistent, asynchronous replication
to a remote data center. The design of such an asynchronous
replication feature is the goal of this project.  This feature would
enable reliable data center fail-over. One of the largest challenges
in implementing this feature is obtaining a consistent snapshot of the
total data set at a given point in time. A consistent snapshot here
means a partition of the set of events (reads and writes) in the
cluster such that there is no event excluded from the snapshot that an
event included in the snapshot depends on. In other words, for any
event pair $e_1$ and $e_2$, if $e_2$ depends on $e_1$, and $e_2$ is
included in the snapshot, so is $e_1$. This consistency is necessary
from the point of view of a client to the file system.

Because Ceph clusters have no controller nodes with a full picture of
the system, there are unusual challenges to acquiring a complete
picture of the system at any given moment in time. Ceph is strongly
consistent, so a potential solution is further complicated: everything
that a particular piece of data relies on must also be available. For
this problem, a snapshot is allowed to be slightly out of date, but it
must present a state the file system actually could have occupied at
some point in the past. To have older but consistent data is
preferable to newer but inconsistent data. Even losing data is better
than having inconsistent data. This consistency must hold from the
perspective of a client. The cluster cannot not assume that it has
full knowledge of event dependencies, because clients are allowed to
carry out out-of-band communication among themselves.

For example, there could be a pair of databases being written to a
Ceph filesystem via different clients. These databases could both be
backing the same web application, which reads from one and then writes
to the other based on that read. Since the web application did this
via two separate clients, we have no way of knowing that the read
caused the write.

The Ceph architecture is designed to grow to scale to clusters of
arbitrary size, so scalability and performance are important concerns
as well. The time necessary to snapshot in any proposed solution must
not severely increase as more clients and nodes are added. In some
production scenarios, snapshots must occur with a minimum frequency
regardless of cluster size. Similarly, snapshots must have negligible
impact on cluster read and write performance. One way to provide a
consistent snapshot is to simply block all reads and writes to the
Ceph file system while the state of the system is gathered. However,
this solution would have a substantial impact on input/output
operations so we can reject it out of hand.

At the scale of a Ceph deployment, nodes fail routinely. Any
solution must take this into account and treat failures as the rule,
not the exception. A solution must consider the impact of node
failures on the consistency of a snapshot and be able to adapt
accordingly. Similarly, a potential solution must assume that
components on which it relies can fail at any time.
