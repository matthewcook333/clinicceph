\chapter{Description of Problem}
\label{sec:description}

Ceph currently implements a robust and performant file system for storing
with strong consistency client data in a single physical data center. 
However, Ceph currently does not provide a mechanism to perform a full cluster
snapshot, and thus cannot support consistent, asynchronous replication
to a remote data center. The design of such an asynchronous
replication feature is the goal of this project.  This feature would
enable reliable data center fail-over. One of the largest challenges
in implementing this feature is obtaining a consistent snapshot of the
total data set at a given point in time. A consistent snapshot here
means a partition of the set of events (reads and writes) in the
cluster such that there is no event excluded from the snapshot that an
event included in the snapshot depends on. For our purposes, an event 
depends on another event if a computer with some knowledge of the 
file system (client or server) could definitively order the events in time.
This consistency guarantee allows file system clients to make
assumptions about the data available in the file system. 

In order to take a snapshot, we need a process for acquiring necessary
information about the system.
Because Ceph clusters have no controller nodes with a full picture of
the system, there are unusual challenges to acquiring a complete
picture of the system at any given moment in time. Ceph is strongly
consistent, so a potential solution is further complicated: everything
that a particular piece of data relies on must also be available. For
this problem, a snapshot is allowed to be slightly out of date, but it
must present a state the file system actually could have occupied at
some point in the past. To have older but consistent data is
preferable to newer but inconsistent data. Even losing data is better
than having inconsistent data. This consistency must hold from the
perspective of a client. The cluster cannot not assume that it has
full knowledge of event dependencies, because clients are allowed to
carry out out-of-band communication among themselves.

For example, a pair of clients could be separately accessing a pair
of object in the Ceph file system. These clients could both be
controlled by the same application. The application may read from 
(or write to) one 
object, through the first client. As a result of this operation,
the application then may decide to write to the second object 
through the second client. Since these operations are 
handled by separate clients, we have no way of knowing that the first
operation caused the second.

The Ceph architecture is designed to grow to scale to clusters of
arbitrary size, so scalability and performance are important concerns
as well. The time necessary to snapshot in any proposed solution must
not severely increase as more clients and nodes are added. In some
production scenarios, snapshots must occur with a minimum frequency
regardless of cluster size. Similarly, snapshots must have negligible
impact on cluster read and write performance. As an example of 
a naive, unworkable solution, consider taking a snapshot by 
simply blocking all operations in a data center until the necessary
information can be gathered. This solution would clearly have too
substantial impact on input/output
operations.

At the scale of a Ceph deployment, nodes fail routinely. Any
solution must take this into account and treat failures as the rule,
not the exception. A solution must consider the impact of node
failures on the consistency of a snapshot and be able to adapt
accordingly. Similarly, a potential solution must assume that
components on which it relies can fail at any time.
