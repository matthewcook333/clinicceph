\chapter{Related Work}
\label{sec:rel-work}

Creating a consistent snapshot of a Ceph cluster is difficult because
Ceph is inherently distributed. The system does not have a single or
small group of controller nodes that track every transaction. Instead,
the cluster must aggregate knowledge from thousands of nodes to
capture a complete point-in-time snapshot of the data in the
cluster. Significant research efforts have been directed toward taking
snapshots and synchronizing events in distributed systems. The
approaches we reviewed, however, are not by themselves viable
solutions to replication problem this project addresses.

\section{Logical Clocks}

Lamport clocks use a logical clock to establish a partial ordering of
events in distributed systems. If an ordering of the events and
messages between nodes in a distributed system can be established, and
this ordering is complete enough to take into account all
dependencies, a snapshot may be obtained by observing which events
happen before other events. Lamport clocks try to order events and
messages by a logical timestamp that increments between each event or
message pass, rather than by some physical time that could be affected
by clock drift. This ordering method works well if the system can
reason about events that are occurring between its own nodes. However,
this type of partial ordering fails to guarantee correct ordering in
the case of out-of-band communication; the system cannot order the
events that occur outside of the system as it has no knowledge of the
order of those events. About events that occur strictly within the
Ceph cluster, Lamport clocks may still be useful for reasoning about
order, but they would have to be used in conjunction with some notion
of physical time, or a method of guaranteeing that dependent data from
out-of-band communications can still be correctly ordered (TODO Cite
Lamport, 1978).

Vector clocks function very similarly to Lamport clocks. However,
rather than storing a single logical time, it stores a vector of times
that each represent the last time seen on a given node in the
system. The ordering of events is based on the relative times stored
in the vectors. All messages contain the vector of the process that
sent it and a process updates its vectors when it receives a
message. The benefit of using vector clocks over Lamport clocks is
that vector clocks do not assign an arbitrary time to the
event. Instead, it uses the relative times of the processes to
determine the partial order of the events. However, like Lamport
clocks, out-of-band communication is not accounted for and events
could be incorrectly ordered (TODO cite Fidge, 1988).

\section{Network Time Synchronization}

Another approach to event ordering is to use timestamps. This approach
has the benefit of a, theoretical, total ordering including in
scenarios with out-of-band communication. However, this approach is
not as simple as one would first expect. As multiple time sources are
in use in a distributed system, the clocks must be synchronized to a
high degree of accuracy in order to use timestamps to order events
across nodes.

A naive approach to a distributed snapshot algorithm uses timestamps
alone to establish a total ordering of events in a system. This works
well in systems with centralized controllers or logs that have
knowledge of all events. However, in a system with highly distributed
control like Ceph, each node only sees a small fraction of
events. Each node contains its own clock, and these clocks tend to
drift perceptibly over time. Clock skew is generated across a
distributed system as clocks drift out of sync. Clocks across a
cluster must be synchronized regularly for a timestamp based solution
to stay temporally consistent.

To illustrate issues with temporal consistency, consider an example
with a cluster containing multiple nodes. Within this cluster,
consider event i and event j such that j depends on i. Without some
method of ensuring bounded clock drifts, it is impossible to guarantee
that a given timestamp at a specific node is correct with reference to
the entire system. One node (with perhaps a slightly fast clock) may
claim that event i occurred at a later point in time than the event
really happened according to some observer. Event j, processed by a
node with a slightly slow clock, could then “occur” ( be timestamped)
before event i. A snapshot algorithm might now believe it is
acceptable to include event j and not event i. Such a snapshot would
be inconsistent.

A synchronization algorithm could be effective, however, should it
provide sufficient, provable bounds on the drift of a given clock and
on the skew across the distributed system. These bounds would allow
the file system to gain a clear understanding of what knowledge of
event ordering it has when taking a snapshot.

Many clock synchronization algorithms already exist and are in wide
use. However, these algorithms tend to have major shortcomings when
they are considered for application to this problem in a hyper-scale
data center. A synchronization method with provable bounds and
reasonable communication complexity is required if we are to use only
timestamps for ordering events in a snapshot. We must also be able to
prove the correctness of the error bound calculations in order for
Ceph to make guarantees about the consistency of its snapshots.

\subsection{Network Time Protocol}

NTP is a robust algorithm for time synchronization (TODO D. Mills et
al., 2010). Currently it is among the most popular time
synchronization algorithms. NTP’s is designed synchronize
geographically disparate computers over the internet. As a result, it
is resilient to node failure, network inconsistencies, and poor clock
quality. NTP requires very little information about the network and
nodes on which it is operating in order to provide useful
synchronization. It uses a number of statistical estimators to predict
future clock performance from previous performance. Of particular note
to our algorithm, NTP does define a maximum error term in relation to
a single, root time source. As a result, NTP is an appropriate choice
for a network time protocol in our algorithm.

A better solution is possible, however. NTP’s focus on robustness
causes compromises for the freeze time. NTP consistently overestimates
uncertainty. A protocol more explicitly designed for local area
network synchronization could likely do away with some of the
complexity of NTP, make more assumptions about network configuration,
and as a result provide tighter bounds on the time.

In this report, we analyze the performance of an NTP implementation,
ntpd, across various clock and network conditions. The ntpd daemon was
chosen for it common use and ease of access to relevant calculated
parameters <TODO citation>. Chrony is another potential choice for an NTP
implementation <TODO citation>, although it lacks some diagnostic
reporting.

\subsection{Precision Time Protocol}

PTP claims to be good for tightly synchronizing computers on a local
network <TODO citation>. Our preliminary testing suggested that this was
the case. To gain even better synchronization, a user may use
specialized hardware (that is relatively commonly supported and
currently in use) to decrease the amount of random variation in
message latency in a network. This allows the protocol to get
extremely accurate measurements of time, and in theory also extremely
tight uncertainty bounds. However, the protocol does not specify, and
the implementation does not include, an upper bound error value. This
means that this protocol is not currently suited for use with our
algorithm.

If performance of NTP is found to be unsatisfactory however, it would
be worth considering extending PTP (<TODO reference implementation
details>) -- the implementation of a maximum error term -- would be
advisable. Linux PTP is an implementation of the Precision Time
Protocol (PTP) <TODO citation>. PTPd is another implementation <TODO
citation>.

\subsection{Wireless Synchronization}

Surprisingly, wireless time synchronization is a much easier
problem. Wireless signal propagation times are very easy to model and
as a result time synchronization is easy to perform with a very high
level of accuracy. Protocols such as PulseSync take advantage of this
observation <TODO citation>.

If extremely small freeze windows are a requirement, a wireless
synchronization protocol could easily be designed that would allow for
a very high level of confidence. However, this would necessitate a
significant amount of specialized hardware. This would be counter to
the project’s goal of getting the most performance possible out of
commodity hardware.

GPS Synchronization is a special case of wireless synchronization that
can provide a nearly perfect time source anywhere around the world. It
is advisable to incorporate a GPS time source (or similarly accurate
time source) into the master clock of any implementation of our
algorithm <TODO REFERENCE IMPLEMENTATION SECTION>.

\section{TrueTime}

Google has a number of very time-sensitive applications, most notably
the synchronously georeplicated Spanner database. Synchronous
georeplication of database transactions requires very strong time
guarantees because database transaction ordering is important. A
library called TrueTime was developed to support these applications.

\subsection{TrueTime.now()}

TrueTime does not provide current time in the way that most time
libraries do. Instead, it gives a range that is guaranteed to contain
the current time. The bounds are claimed to be generally less than 10
milliseconds. This allows for very rapid throughput on the database
while still maintaining definitive transaction ordering. When
TrueTime’s guaranteed bounds start to spread, it will throttle writes
to maintain that ordering (TODO Corbett et al., 2012).

\subsection{TrueTime's Clocks}

TrueTime relies on having extremely good clocks to maintain sub-10ms
skew between geographically diverse data centers. Specifically, Google
has placed atomic and GPS clocks in their data centers. TrueTime runs
a daemon that talks to these clocks, both in its own data center and
in others. A variation on Marzullo’s algorithm is used to weed out
clocks whose timing information is not reliable (e.g. due to network
latency) (TODO Corbett et al., 2012).

\subsection{Applicability}

As a concept, TrueTime is interesting. However, as it is a proprietary
library and as it requires special hardware, it would not be able to
be used directly as a solution to Ceph’s asynchronous replication
problem. However, if a similar open source protocol became available,
it could merit deeper analysis. %% TODO This exists, we talked about
                                %% it, it's called Cockroach
